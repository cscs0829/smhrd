import time
import requests
import pandas as pd
from bs4 import BeautifulSoup

# âœ… ì¡ì½”ë¦¬ì•„ ê³µê³  í¬ë¡¤ë§ í•¨ìˆ˜
def crawl_jobkorea():
    job_data = []
    BASE_URL = "https://www.jobkorea.co.kr/Search/?stext=%EB%B0%B1%EC%97%94%EB%93%9C&ord=RegDtDesc&duty=1000229%2C1000231%2C1000232%2C1000239%2C1000233&careerType=1&tabType=recruit&Page_No={}"

    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
    }

    for i in range(1, 4):  # âœ… 1~3 í˜ì´ì§€ í¬ë¡¤ë§
        print(f"ğŸ“„ ì¡ì½”ë¦¬ì•„ {i} í˜ì´ì§€ í¬ë¡¤ë§ ì¤‘...")
        url = BASE_URL.format(i)

        response = requests.get(url, headers=headers)
        soup = BeautifulSoup(response.text, 'html.parser')

        job_listings = soup.select('.list-item')  # âœ… ê³µê³  ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°

        for job in job_listings:
            rec_idx = int(job['data-gno']) if 'data-gno' in job.attrs else 0
            company_tag = job.select_one('.list-section-corp .corp-name-link')
            company_name = company_tag.get_text(strip=True) if company_tag else "ì •ë³´ ì—†ìŒ"
            job_title_tag = job.select_one('.list-section-information .information-title-link')
            job_title = job_title_tag.get_text(strip=True) if job_title_tag else "ì •ë³´ ì—†ìŒ"
            work_place_tag = job.select_one('.chip-information-group .chip-information-item:nth-of-type(4)')
            work_place_text = work_place_tag.get_text(strip=True) if work_place_tag else "ì •ë³´ ì—†ìŒ"
            job_sector_tag = job.select_one('.list-section-information .information-title')
            job_sector_text = job_sector_tag.get_text(strip=True).replace("\n", ", ") if job_sector_tag else "ì •ë³´ ì—†ìŒ"
            job_link = f"https://www.jobkorea.co.kr/Recruit/GI_Read/{rec_idx}" if rec_idx else "ì •ë³´ ì—†ìŒ"

            job_data.append({
                "rec_idx": rec_idx,
                "ê¸°ì—…ëª…": company_name,
                "ê³µê³  ì œëª©": job_title,
                "ê·¼ë¬´ì§€": work_place_text,
                "ì§ë¬´": job_sector_text,
                "ë§í¬": job_link
            })

        time.sleep(1)  # âœ… ì„œë²„ ë¶€í•˜ ë°©ì§€

    return job_data

# âœ… ì‹¤í–‰ í•¨ìˆ˜
def run():
    print("ğŸ” ì¡ì½”ë¦¬ì•„ ê³µê³  í¬ë¡¤ë§ ì‹œì‘...")
    job_data = crawl_jobkorea()
    df = pd.DataFrame(job_data)
    df.to_csv("jobkorea_jobs.csv", index=False, encoding="utf-8-sig")
    print("âœ… í¬ë¡¤ë§ ì™„ë£Œ! CSV íŒŒì¼ ì €ì¥ë¨: jobkorea_jobs.csv")

# ì‹¤í–‰
run()
